{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Ensemble Learning in machine learning? Explain the key idea\n",
        "behind it.\n",
        "- Ensemble Learning in machine learning refers to a technique where multiple models (often called \"weak learners\") are combined to create a stronger, more accurate predictive model.\n",
        "\n",
        " Key Idea Behind Ensemble Learning\n",
        "\n",
        "The core idea is:\n",
        "\n",
        "“A group of weak models, when combined properly, can perform better than any single strong model.”\n",
        "\n",
        "This approach leverages the diversity and strengths of individual models to reduce errors, increase accuracy, and improve generalization on unseen data.\n",
        "\n",
        "2. What is the difference between Bagging and Boosting?\n",
        "- | Feature              | **Bagging**                                              | **Boosting**                                     |\n",
        "| -------------------- | -------------------------------------------------------- | ------------------------------------------------ |\n",
        "| **Goal**             | Reduce **variance**                                      | Reduce **bias** and **variance**                 |\n",
        "| **Model Training**   | **Parallel** (independent models)                        | **Sequential** (each model learns from errors)   |\n",
        "| **Data Sampling**    | **Bootstrap sampling** (random with replacement)         | Focus on **misclassified** or hard examples      |\n",
        "| **Model Weighting**  | All models have **equal weight**                         | Models are **weighted** based on performance     |\n",
        "| **Focus**            | Treats all samples equally                               | Focuses more on **hard-to-predict** instances    |\n",
        "| **Overfitting Risk** | Lower (more stable)                                      | Higher (needs careful tuning)                    |\n",
        "| **Prediction**       | **Voting** (classification) / **Averaging** (regression) | **Weighted voting** or summation                 |\n",
        "| **Examples**         | **Random Forest**, Bagged Trees                          | **AdaBoost**, **XGBoost**, **Gradient Boosting** |\n",
        "\n",
        "\n",
        "3. What is bootstrap sampling and what role does it play in Bagging methods\n",
        "like Random Forest?\n",
        "- hat is Bootstrap Sampling?\n",
        "\n",
        "Bootstrap sampling is a statistical technique where:\n",
        "\n",
        "You create multiple random samples from the original dataset.\n",
        "\n",
        "Each sample is drawn with replacement, meaning:\n",
        "\n",
        "The same data point can appear more than once in a sample.\n",
        "\n",
        "Some data points may not appear at all in a given sample.\n",
        "\n",
        "Each bootstrap sample is typically the same size as the original dataset.\n",
        "\n",
        " Role of Bootstrap Sampling in Bagging (e.g., Random Forest)\n",
        "\n",
        "In Bagging (Bootstrap Aggregating) methods like Random Forest, bootstrap sampling is crucial because it introduces diversity among the models (e.g., decision trees). Here's how it works:\n",
        "\n",
        " Steps in Bagging with Bootstrap:\n",
        "\n",
        "Generate multiple bootstrap samples from the training data.\n",
        "\n",
        "Train a separate model (e.g., a decision tree) on each sample.\n",
        "\n",
        "Aggregate predictions:\n",
        "\n",
        "For classification: majority vote.\n",
        "\n",
        "For regression: average.\n",
        "\n",
        "4. What are Out-of-Bag (OOB) samples and how is OOB score used to\n",
        "evaluate ensemble models?\n",
        "- What are Out-of-Bag (OOB) Samples?\n",
        "\n",
        "When using bootstrap sampling, each model (e.g., decision tree) is trained on a random sample with replacement from the original dataset.\n",
        "\n",
        "Because sampling is with replacement, about 63% of the data points end up in any one bootstrap sample (on average).\n",
        "\n",
        "The remaining ~37% of the data is not included in that particular sample.\n",
        "\n",
        "These excluded samples are called Out-of-Bag (OOB) samples.\n",
        "\n",
        " OOB samples are like \"built-in\" validation data for each model.\n",
        "\n",
        " How is the OOB Score Used for Evaluation?\n",
        "\n",
        "The OOB score is a way to evaluate the performance of ensemble models without needing a separate validation set.\n",
        "\n",
        " How it works:\n",
        "\n",
        "Train each model (e.g., tree) on its bootstrap sample.\n",
        "\n",
        "For each data point, collect predictions from only the models that did not see it during training (i.e., where it was OOB).\n",
        "\n",
        "Aggregate these predictions (e.g., majority vote or average).\n",
        "\n",
        "Compare the aggregated OOB predictions to the actual labels.\n",
        "\n",
        "Compute accuracy, MSE, or another appropriate metric — this is the OOB score.\n",
        "\n",
        "5. Compare feature importance analysis in a single Decision Tree vs. a\n",
        "Random Forest.\n",
        "- | Aspect                     | **Decision Tree**                                              | **Random Forest**                                              |\n",
        "| -------------------------- | -------------------------------------------------------------- | -------------------------------------------------------------- |\n",
        "| **Computation**            | Based on impurity reduction in a **single tree**               | Averaged impurity reduction across **many trees**              |\n",
        "| **Stability**              | **Low** – sensitive to data changes                            | **High** – more robust due to averaging                        |\n",
        "| **Interpretability**       | High – easy to trace through tree structure                    | Moderate – less intuitive due to multiple trees                |\n",
        "| **Bias Toward Features**   | More **biased** toward high-cardinality or continuous features | **Less biased**, but still possible without correction         |\n",
        "| **Accuracy of Importance** | Rough estimate – may overfit                                   | More reliable – better generalization                          |\n",
        "| **Overfitting Risk**       | Higher – single tree may overfit                               | Lower – ensemble reduces overfitting                           |\n",
        "| **Advanced Options**       | Limited                                                        | Supports **permutation importance** for more accurate insights |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-v61auy7WQMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' 6. Write a Python program to:\n",
        "● Load the Breast Cancer dataset using\n",
        "sklearn.datasets.load_breast_cancer()\n",
        "● Train a Random Forest Classifier\n",
        "● Print the top 5 most important features based on feature importance scores.\n",
        "'''\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get feature importance scores\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Create a DataFrame for easy sorting\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Sort by importance (descending) and get top 5\n",
        "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(5)\n",
        "\n",
        "# Print the top 5 features\n",
        "print(\"Top 5 Most Important Features:\\n\")\n",
        "print(top_features.to_string(index=False))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haUqIplKXvkq",
        "outputId": "db4a4a84-dc1e-4d6a-ef2c-8c5d40687f62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "\n",
            "             Feature  Importance\n",
            "          worst area    0.139357\n",
            "worst concave points    0.132225\n",
            " mean concave points    0.107046\n",
            "        worst radius    0.082848\n",
            "     worst perimeter    0.080850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "8. Write a Python program to:\n",
        "● Train a Random Forest Classifier\n",
        "● Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "● Print the best parameters and final accuracy\n",
        "'''\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [None, 3, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best model and parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params)\n",
        "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA5Upq9MYF7L",
        "outputId": "7eac949b-a855-4709-d808-1588c74e068e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "{'max_depth': 3, 'n_estimators': 10}\n",
            "Final Test Accuracy: 0.9111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. You are working as a data scientist at a financial institution to predict loan\n",
        "default. You have access to customer demographic and transaction history data.\n",
        "You decide to use ensemble techniques to increase model performance.\n",
        "Explain your step-by-step approach to:\n",
        "● Choose between Bagging or Boosting\n",
        "● Handle overfitting\n",
        "● Select base models\n",
        "● Evaluate performance using cross-validation\n",
        "● Justify how ensemble learning improves decision-making in this real-world\n",
        "context\n",
        "- 1. Choose Between Bagging or Boosting\n",
        "\n",
        "Goal: Improve predictive accuracy and robustness on complex financial data.\n",
        "\n",
        "Bagging (e.g., Random Forest):\n",
        "\n",
        "Reduces variance by averaging many independent models.\n",
        "\n",
        "Works well if the base models tend to overfit (like deep trees).\n",
        "\n",
        "Good starting point if the data is noisy or has many irrelevant features.\n",
        "\n",
        "Boosting (e.g., XGBoost, LightGBM, AdaBoost):\n",
        "\n",
        "Sequentially focuses on hard-to-predict cases, reducing bias and variance.\n",
        "\n",
        "Often achieves better accuracy but can overfit if not carefully tuned.\n",
        "\n",
        "Typically better for tabular data and structured problems like loan default.\n",
        "\n",
        "Approach:\n",
        "\n",
        "Start with Bagging for a robust baseline.\n",
        "\n",
        "Experiment with Boosting to potentially gain better accuracy, especially if error patterns show systematic bias.\n",
        "\n",
        "Compare models based on validation results.\n",
        "\n",
        "2. Handle Overfitting\n",
        "\n",
        "In Bagging:\n",
        "\n",
        "Limit tree depth or use pruning.\n",
        "\n",
        "Use enough base estimators (trees) to stabilize predictions.\n",
        "\n",
        "Use out-of-bag (OOB) error to monitor overfitting without separate validation.\n",
        "\n",
        "In Boosting:\n",
        "\n",
        "Use learning rate (shrinkage) to slow learning and prevent overfitting.\n",
        "\n",
        "Limit tree depth and number of estimators.\n",
        "\n",
        "Use early stopping based on validation set or cross-validation.\n",
        "\n",
        "General Techniques:\n",
        "\n",
        "Feature selection or dimensionality reduction.\n",
        "\n",
        "Regularization parameters (L1, L2).\n",
        "\n",
        "Data augmentation or balancing techniques if classes are imbalanced.\n",
        "\n",
        "3. Select Base Models\n",
        "\n",
        "Decision Trees are commonly used as base learners because:\n",
        "\n",
        "They handle mixed data types well.\n",
        "\n",
        "They capture non-linear relationships.\n",
        "\n",
        "For Bagging:\n",
        "\n",
        "Use deep trees since bagging reduces variance.\n",
        "\n",
        "For Boosting:\n",
        "\n",
        "Use shallow trees (e.g., depth 3–5) to keep weak learners.\n",
        "\n",
        "Optionally:\n",
        "\n",
        "Experiment with other base models if needed (e.g., logistic regression in some boosting frameworks).\n",
        "\n",
        "4. Evaluate Performance Using Cross-Validation\n",
        "\n",
        "Use Stratified K-Fold Cross-Validation because:\n",
        "\n",
        "Loan default is often imbalanced (few defaults vs many non-defaults).\n",
        "\n",
        "Stratification preserves the percentage of default classes in each fold.\n",
        "\n",
        "Metrics to evaluate:\n",
        "\n",
        "ROC-AUC (good for binary classification and imbalanced data).\n",
        "\n",
        "Precision, Recall, F1-score (especially recall for catching defaults).\n",
        "\n",
        "Confusion Matrix to understand false positives/negatives.\n",
        "\n",
        "Also consider:\n",
        "\n",
        "Use OOB error for bagging methods as a fast, unbiased estimate.\n",
        "\n",
        "For boosting, use early stopping with a validation fold during training.\n",
        "\n",
        "5. Justify How Ensemble Learning Improves Decision-Making\n",
        "\n",
        "More accurate predictions help the institution better identify risky borrowers, reducing loan defaults.\n",
        "\n",
        "Reduced variance and bias means the model generalizes better on unseen customers.\n",
        "\n",
        "Robustness to noisy, high-dimensional data from demographics and transaction history.\n",
        "\n",
        "Confidence in decisions: Aggregating many models leads to stable, reliable scores.\n",
        "\n",
        "Allows for better resource allocation (e.g., focusing credit checks or interventions on high-risk borrowers).\n",
        "\n",
        "Supports regulatory compliance by providing interpretable feature importances and consistent performance."
      ],
      "metadata": {
        "id": "QX1RmYK2Y5rK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b9hC3tgvYqlI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}